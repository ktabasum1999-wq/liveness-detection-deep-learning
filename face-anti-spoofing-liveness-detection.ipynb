{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2289782,"sourceType":"datasetVersion","datasetId":1371510},{"sourceId":11186244,"sourceType":"datasetVersion","datasetId":4912459}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# *Detect whether a face image/video is a live person or a spoof (printed photo / replay on screen / optionally mask).*****","metadata":{}},{"cell_type":"markdown","source":"# Inspection cell","metadata":{}},{"cell_type":"code","source":"# Fast structured listing up to depth 3 (run in your Kaggle notebook)\nfrom pathlib import Path\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport os\n\nROOTS = [\n    Path(\"/kaggle/input/celeba-spoof-for-face-antispoofing\"),\n    Path(\"/kaggle/input/photo-print-attacks-dataset-1k-individuals\")\n]\n\nIMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tiff\")\nMAX_SUBFOLDERS = 200  # safety cap\n\ndef list_folder(path, max_sub=MAX_SUBFOLDERS):\n    if not path.exists():\n        print(f\"Path not found: {path}\\n\"); return\n    print(f\"\\n=== ROOT: {path} ===\")\n    top_children = sorted([p for p in path.iterdir()])\n    print(\"Top-level entries (first 50):\")\n    for i,c in enumerate(top_children[:50]):\n        print(\" \", i+1, c.name, \"(dir)\" if c.is_dir() else \"(file)\")\n    # check immediate subfolders (depth=1)\n    checked = 0\n    for child in top_children:\n        if checked >= max_sub: break\n        if child.is_dir():\n            checked += 1\n            # count images directly inside this child (non-recursive)\n            files = [f for f in child.iterdir() if f.is_file() and f.suffix.lower() in IMG_EXTS]\n            subdirs = [d for d in child.iterdir() if d.is_dir()]\n            print(f\"\\n-- {child.relative_to(path)} -- images_here: {len(files)} , subdirs: {len(subdirs)}\")\n            # show up to 3 example image filenames\n            for ex in files[:3]:\n                print(\"    img:\", ex.name)\n            # list up to 6 immediate sub-subfolders and show their image counts (depth=2)\n            for j, sd in enumerate(subdirs[:6]):\n                imgs_sd = [f for f in sd.iterdir() if f.is_file() and f.suffix.lower() in IMG_EXTS]\n                print(f\"    subdir: {sd.name} -> images_here: {len(imgs_sd)} (examples: {[f.name for f in imgs_sd[:3]]})\")\n    # Also detect any large archives at root\n    archives = [f for f in path.iterdir() if f.is_file() and f.suffix.lower() in (\".zip\",\".rar\",\".tar\",\".gz\")]\n    if archives:\n        print(\"\\nArchives found at root:\")\n        for a in archives:\n            print(\" \", a.name, \"-\", a.stat().st_size//1024, \"KB\")\n    print(\"\\n(End of listing for this root)\\n\")\n\nfor r in ROOTS:\n    list_folder(r)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:13:50.852404Z","iopub.execute_input":"2025-12-07T16:13:50.853112Z","iopub.status.idle":"2025-12-07T16:13:50.902650Z","shell.execute_reply.started":"2025-12-07T16:13:50.853068Z","shell.execute_reply":"2025-12-07T16:13:50.901805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport subprocess, shlex\n\nroots = [\n    Path(\"/kaggle/input/celeba-spoof-for-face-antispoofing\"),\n    Path(\"/kaggle/input/photo-print-attacks-dataset-1k-individuals\")\n]\n\nfor root in roots:\n    print(f\"\\n=== PROBING {root} ===\")\n    if not root.exists():\n        print(\"NOT FOUND\")\n        continue\n    # find first image quickly using shell find (stops at first match)\n    cmd = f\"find {shlex.quote(str(root))} -type f \\\\( -iname '*.jpg' -o -iname '*.jpeg' -o -iname '*.png' \\\\) -print -quit\"\n    try:\n        res = subprocess.check_output(cmd, shell=True, stderr=subprocess.DEVNULL).decode().strip()\n    except subprocess.CalledProcessError:\n        res = \"\"\n    if not res:\n        print(\"No image found quickly (may be inside archives or very deep).\")\n        continue\n    print(\"First image found:\", res)\n    parent = Path(res).parent\n    print(\"Parent dir:\", parent)\n    print(\"Listing parent dir (first 50 entries):\")\n    for i, p in enumerate(sorted(parent.iterdir())[:50]):\n        print(\" \", p.name)\n    # show first 6 image files from that parent\n    imgs = [p for p in sorted(parent.iterdir()) if p.is_file() and p.suffix.lower() in ('.jpg','.jpeg','.png')][:6]\n    print(\"First image files in that dir:\")\n    for p in imgs:\n        try:\n            from PIL import Image\n            with Image.open(p) as im:\n                print(\" \", p.name, \"->\", im.size)\n        except Exception:\n            print(\" \", p.name, \"-> could not open\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:21:52.972858Z","iopub.execute_input":"2025-12-07T16:21:52.973167Z","iopub.status.idle":"2025-12-07T16:21:53.759852Z","shell.execute_reply.started":"2025-12-07T16:21:52.973146Z","shell.execute_reply":"2025-12-07T16:21:53.758925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Create a sampled dataset from the CelebA-Spoof Data folder (quick)**","metadata":{}},{"cell_type":"code","source":"# Run this in a Python cell in your Kaggle notebook (fast, targeted sampling)\nfrom pathlib import Path\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport shutil, random, sys\n\n# CONFIG: lower N_PER_CLASS if you want even faster (e.g., 20)\nN_PER_CLASS = 60\n\nSRC1 = Path(\"/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/Data\")\nSRC2 = Path(\"/kaggle/input/photo-print-attacks-dataset-1k-individuals\")\nDST = Path(\"/kaggle/working/dataset_sampled\")\n\n# helper label detection\ndef detect_label_from_path(p:Path):\n    s = str(p).lower()\n    if any(k in s for k in (\"live\",\"real\",\"genuine\")):\n        return \"real\"\n    if any(k in s for k in (\"spoof\",\"attack\",\"print\",\"replay\",\"photo\",\"display\",\"screen\",\"fake\")):\n        return \"spoof\"\n    return None\n\n# create folders\nfor split in (\"train\",\"val\",\"test\"):\n    for lbl in (\"real\",\"spoof\"):\n        (DST/split/lbl).mkdir(parents=True, exist_ok=True)\n\ndef sample_from_root(root:Path, n_per_class=N_PER_CLASS, verbose=True):\n    if not root.exists():\n        if verbose: print(f\"[skip] {root} not found\")\n        return {\"real\":0,\"spoof\":0}\n    real_count = 0\n    spoof_count = 0\n    # Only walk limited levels: root/*/*/*  (three levels) which matches Data/<split>/<id>/<live_or_spoof>/images\n    # This avoids scanning everything.\n    top_children = [c for c in sorted(root.iterdir()) if c.is_dir()]\n    for a in top_children:\n        if real_count >= n_per_class and spoof_count >= n_per_class:\n            break\n        # examine a's children (level 2)\n        for b in sorted(a.iterdir()):\n            if real_count >= n_per_class and spoof_count >= n_per_class:\n                break\n            if not b.is_dir():\n                continue\n            # examine level 3 (likely the live/spoof folders)\n            for c in sorted(b.iterdir()):\n                if not c.is_dir():\n                    continue\n                # decide label\n                lbl = detect_label_from_path(c)\n                if lbl is None:\n                    # fallback: if c contains files, open one to see name; else continue\n                    # try to use folder name as hint\n                    name = c.name.lower()\n                    if any(k in name for k in (\"live\",\"real\",\"genuine\")):\n                        lbl=\"real\"\n                    elif any(k in name for k in (\"spoof\",\"attack\",\"print\",\"replay\",\"photo\",\"display\",\"screen\",\"fake\")):\n                        lbl=\"spoof\"\n                    else:\n                        continue\n                # gather image files in this folder (non-recursive)\n                imgs = [f for f in sorted(c.iterdir()) if f.is_file() and f.suffix.lower() in (\".jpg\",\".jpeg\",\".png\")]\n                if not imgs:\n                    continue\n                # copy up to remaining items for this label\n                remaining = n_per_class - (real_count if lbl==\"real\" else spoof_count)\n                to_take = imgs[:remaining]\n                for f in to_take:\n                    # random split\n                    r=random.random()\n                    if r<0.7: split=\"train\"\n                    elif r<0.85: split=\"val\"\n                    else: split=\"test\"\n                    dstp = DST/split/lbl/f\"{a.name}_{b.name}_{c.name}_{f.name}\"\n                    try:\n                        shutil.copy(f, dstp)\n                    except Exception:\n                        pass\n                    if lbl==\"real\":\n                        real_count += 1\n                    else:\n                        spoof_count += 1\n                    if real_count >= n_per_class and spoof_count >= n_per_class:\n                        break\n    if verbose:\n        print(f\"Sampled from {root.name if root.exists() else root}: real={real_count}, spoof={spoof_count}\")\n    return {\"real\":real_count,\"spoof\":spoof_count}\n\n# Run sampling on CelebA Data (targeted)\ncounts1 = sample_from_root(SRC1, N_PER_CLASS)\n\n# Try SRC2 quickly: it may have a different structure; attempt to find immediate subfolders containing images\ndef sample_src2(src, n_per_class=N_PER_CLASS):\n    if not src.exists():\n        print(f\"[skip] {src} not found\")\n        return {\"real\":0,\"spoof\":0}\n    real_count = 0\n    spoof_count = 0\n    # list immediate subfolders (sample only first 200 to be safe)\n    subs = [d for d in sorted(src.iterdir()) if d.is_dir()][:200]\n    for s in subs:\n        # collect image files in s and its immediate subdirs\n        imgs = []\n        imgs += [f for f in sorted(s.glob(\"*\")) if f.is_file() and f.suffix.lower() in (\".jpg\",\".jpeg\",\".png\")]\n        # check subfolders one level\n        for subsub in [x for x in sorted(s.iterdir()) if x.is_dir()][:10]:\n            imgs += [f for f in sorted(subsub.glob(\"*\")) if f.is_file() and f.suffix.lower() in (\".jpg\",\".jpeg\",\".png\")]\n        if not imgs:\n            continue\n        # decide label heuristically from folder or filenames\n        label = None\n        if any(k in s.name.lower() for k in (\"print\",\"photo\",\"spoof\",\"attack\",\"replay\",\"display\",\"screen\")):\n            label=\"spoof\"\n        else:\n            # inspect names\n            if any(any(k in fname.name.lower() for k in (\"print\",\"photo\",\"spoof\",\"attack\",\"replay\",\"display\",\"screen\")) for fname in imgs[:6]):\n                label=\"spoof\"\n            else:\n                label=\"real\"\n        remaining = n_per_class - (real_count if label==\"real\" else spoof_count)\n        to_take = imgs[:remaining]\n        for f in to_take:\n            r=random.random()\n            if r<0.7: split=\"train\"\n            elif r<0.85: split=\"val\"\n            else: split=\"test\"\n            dstp = DST/split/label/f\"{s.name}_{f.name}\"\n            try:\n                shutil.copy(f, dstp)\n            except Exception:\n                pass\n            if label==\"real\":\n                real_count += 1\n            else:\n                spoof_count += 1\n        if real_count>=n_per_class and spoof_count>=n_per_class:\n            break\n    print(f\"Sampled from {src.name}: real={real_count}, spoof={spoof_count}\")\n    return {\"real\":real_count,\"spoof\":spoof_count}\n\ncounts2 = sample_src2(SRC2, N_PER_CLASS)\n\n# Summary and show a few samples\nprint(\"\\nFINAL COUNTS (dataset_sampled):\")\nfor p in (\"train\",\"val\",\"test\"):\n    r = len(list((DST/p/\"real\").glob(\"*\")))\n    s = len(list((DST/p/\"spoof\").glob(\"*\")))\n    print(f\" {p}: real={r}, spoof={s}\")\n\n# Show up to 3 sample sizes per split/label\nfrom PIL import Image\nfor lbl in [\"train/real\",\"train/spoof\",\"val/real\",\"val/spoof\",\"test/real\",\"test/spoof\"]:\n    p = DST/lbl\n    items = sorted([f for f in p.glob(\"*\")])[:3]\n    print(\"\\n\", lbl, \"->\", len(list(p.glob(\"*\"))), \"examples\")\n    for it in items:\n        try:\n            with Image.open(it) as im:\n                print(\"   \", it.name, \"size\", im.size)\n        except Exception:\n            print(\"   \", it.name, \"-> cannot open\")\n\n# If counts are 0 for both sources, alert user\nif sum(counts1.values())==0 and sum(counts2.values())==0:\n    print(\"\\nWARNING: No samples found. The folder structure may be different. In that case tell me the exact output of the small probe you ran earlier (the 'First image found' path), and I will write a one-line copier for that parent folder.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:37:52.505574Z","iopub.execute_input":"2025-12-07T16:37:52.506479Z","iopub.status.idle":"2025-12-07T16:37:54.905690Z","shell.execute_reply.started":"2025-12-07T16:37:52.506446Z","shell.execute_reply":"2025-12-07T16:37:54.904770Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Install / imports (run once)","metadata":{},"attachments":{"baefd7db-854e-4dcf-a320-03b9ecbc4d88.png":{"image/png":"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"}}},{"cell_type":"code","source":"\n\n\nimport os, math, random, itertools\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\nimport seaborn as sns\nprint(\"TensorFlow version:\", tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:45:48.122642Z","iopub.execute_input":"2025-12-07T16:45:48.123781Z","iopub.status.idle":"2025-12-07T16:45:48.130046Z","shell.execute_reply.started":"2025-12-07T16:45:48.123749Z","shell.execute_reply":"2025-12-07T16:45:48.129130Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data generators","metadata":{}},{"cell_type":"code","source":"# Data generators (adjust BATCH or IMG_SIZE if you want)\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nBASE = \"/kaggle/working/dataset_sampled\"\nIMG_SIZE = (224,224)\nBATCH = 16\n\ntrain_dir = os.path.join(BASE, \"train\")\nval_dir   = os.path.join(BASE, \"val\")\ntest_dir  = os.path.join(BASE, \"test\")\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=10,\n                                   width_shift_range=0.08,\n                                   height_shift_range=0.08,\n                                   shear_range=0.05,\n                                   zoom_range=0.08,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = train_datagen.flow_from_directory(train_dir,\n                                              target_size=IMG_SIZE,\n                                              batch_size=BATCH,\n                                              class_mode='binary',\n                                              shuffle=True)\n\nval_gen = val_datagen.flow_from_directory(val_dir,\n                                          target_size=IMG_SIZE,\n                                          batch_size=BATCH,\n                                          class_mode='binary',\n                                          shuffle=False)\n\ntest_gen = val_datagen.flow_from_directory(test_dir,\n                                          target_size=IMG_SIZE,\n                                          batch_size=1,\n                                          class_mode='binary',\n                                          shuffle=False)\n\nprint(\"Train samples:\", train_gen.samples, \"Val samples:\", val_gen.samples, \"Test samples:\", test_gen.samples)\nprint(\"Class indices:\", train_gen.class_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:48:26.124673Z","iopub.execute_input":"2025-12-07T16:48:26.125038Z","iopub.status.idle":"2025-12-07T16:48:26.151995Z","shell.execute_reply.started":"2025-12-07T16:48:26.125014Z","shell.execute_reply":"2025-12-07T16:48:26.151026Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build MobileNetV2 model","metadata":{}},{"cell_type":"code","source":"# Build MobileNetV2 transfer model (freeze base initially)\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\nbase = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0],IMG_SIZE[1],3))\nx = GlobalAveragePooling2D()(base.output)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.4)(x)\nout = Dense(1, activation='sigmoid')(x)\nmodel = Model(base.input, out)\n\n# Freeze base\nfor layer in base.layers:\n    layer.trainable = False\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:49:09.028559Z","iopub.execute_input":"2025-12-07T16:49:09.028856Z","iopub.status.idle":"2025-12-07T16:49:11.501837Z","shell.execute_reply.started":"2025-12-07T16:49:09.028836Z","shell.execute_reply":"2025-12-07T16:49:11.501088Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Callbacks + Train","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nckpt_path = \"/kaggle/working/antispoof_mobilenet_best.h5\"\ncallbacks = [\n    ModelCheckpoint(ckpt_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6),\n    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n]\n\nEPOCHS = 8\nhistory = model.fit(train_gen,\n                    validation_data=val_gen,\n                    epochs=EPOCHS,\n                    callbacks=callbacks)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:50:36.010969Z","iopub.execute_input":"2025-12-07T16:50:36.011338Z","iopub.status.idle":"2025-12-07T16:51:20.929043Z","shell.execute_reply.started":"2025-12-07T16:50:36.011316Z","shell.execute_reply":"2025-12-07T16:51:20.928315Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optional fine-tune","metadata":{}},{"cell_type":"code","source":"\nfor layer in base.layers[-40:]:\n    layer.trainable = True\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory_ft = model.fit(train_gen, validation_data=val_gen, epochs=6, callbacks=callbacks)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:51:49.921109Z","iopub.execute_input":"2025-12-07T16:51:49.921657Z","iopub.status.idle":"2025-12-07T16:52:35.222322Z","shell.execute_reply.started":"2025-12-07T16:51:49.921629Z","shell.execute_reply":"2025-12-07T16:52:35.221364Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate on test set + classification report","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow.keras.models import load_model\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nif os.path.exists(ckpt_path):\n    model = load_model(ckpt_path)\n\npreds = model.predict(test_gen, verbose=1)\ny_pred = (preds.ravel() > 0.5).astype(int)\ny_true = test_gen.classes\n\nprint(classification_report(y_true, y_pred, target_names=list(test_gen.class_indices.keys())))\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(4,3))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=list(test_gen.class_indices.keys()), yticklabels=list(test_gen.class_indices.keys()))\nplt.xlabel(\"Pred\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:52:55.710726Z","iopub.execute_input":"2025-12-07T16:52:55.711076Z","iopub.status.idle":"2025-12-07T16:52:58.495127Z","shell.execute_reply.started":"2025-12-07T16:52:55.711037Z","shell.execute_reply":"2025-12-07T16:52:58.494121Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Quick Grad-CAM visual (optional)","metadata":{}},{"cell_type":"code","source":"\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nfrom tensorflow.keras.preprocessing import image as kimage\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\n# Ensure 'model' exists (it will if you trained or loaded checkpoint)\ntry:\n    model  # noqa\nexcept NameError:\n    raise RuntimeError(\"Model variable not found. Load or train the model first (run the training / load checkpoint cell).\")\n\n# 1) Safely find a last convolutional layer\nlast_conv = None\nfor l in reversed(model.layers):\n    try:\n        shape = getattr(l, \"output_shape\", None)\n        # some layers expose output_shape as a tuple, some as list; guard with try/except\n        if shape is None:\n            # try to inspect output attribute (Tensor) if available\n            out = getattr(l, \"output\", None)\n            if out is not None:\n                # out.shape is TensorShape\n                shape = getattr(out, \"shape\", None)\n        if shape is not None:\n            # convert TensorShape to tuple if needed\n            try:\n                if hasattr(shape, \"as_list\"):\n                    shp = shape.as_list()\n                else:\n                    shp = tuple(shape)\n            except Exception:\n                shp = None\n            if shp and len(shp) == 4:\n                last_conv = l.name\n                break\n    except Exception:\n        # ignore layers that don't provide shape info\n        continue\n\n# Fallbacks if last_conv still None (common MobileNetV2 conv names)\nif last_conv is None:\n    for candidate in [\"Conv_1\", \"conv_pw_13_relu\", \"block_16_project\", \"block_13_expand\", \"block_16_expand\"]:\n        try:\n            if any(x.name == candidate for x in model.layers):\n                last_conv = candidate\n                break\n        except Exception:\n            continue\n\nif last_conv is None:\n    # As a last resort choose the last layer that has a 4D output tensor by checking output.shape\n    for l in reversed(model.layers):\n        try:\n            out = getattr(l, \"output\", None)\n            if out is None: \n                continue\n            shp = getattr(out, \"shape\", None)\n            if shp is None:\n                continue\n            # TensorShape -> list\n            try:\n                shp_list = shp.as_list()\n            except Exception:\n                shp_list = tuple(shp)\n            if shp_list and len(shp_list) == 4:\n                last_conv = l.name\n                break\n        except Exception:\n            continue\n\nif last_conv is None:\n    raise RuntimeError(\"Could not find a convolutional layer automatically. Please tell me the model architecture or pick a conv layer name manually.\")\n\nprint(\"Using last conv layer:\", last_conv)\n\n# 2) Grad-CAM function (works for binary output with sigmoid)\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, eps=1e-8):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    with tf.GradientTape() as tape:\n        conv_outputs, preds = grad_model(img_array)\n        # preds shape: (1,1) for binary. Use preds[:,0] as loss.\n        loss = preds[:, 0]\n    grads = tape.gradient(loss, conv_outputs)\n    # If grads is None (rare), return zeros\n    if grads is None:\n        return np.zeros(shape=(conv_outputs.shape[1], conv_outputs.shape[2]), dtype=np.float32)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0)\n    denom = tf.math.reduce_max(heatmap) + eps\n    heatmap = heatmap / denom\n    return heatmap.numpy()\n\n# 3) Prepare sample test images (up to 6) from your test folder\nTEST_ROOT = Path(\"/kaggle/working/dataset_sampled/test\")\nIMG_SIZE = (224, 224)  # should match training IMG_SIZE\n\nsamples = []\nfor lbl in (\"real\", \"spoof\"):\n    p = TEST_ROOT / lbl\n    if not p.exists():\n        continue\n    for f in sorted(p.glob(\"*\"))[:3]:\n        samples.append((str(f), lbl))\n# if no samples found, try dataset_quick or dataset folders\nif not samples:\n    alt = Path(\"/kaggle/working/dataset_quick\")\n    for lbl in (\"real\",\"spoof\"):\n        p = alt / \"train\" / lbl\n        if p.exists():\n            for f in sorted(p.glob(\"*\"))[:3]:\n                samples.append((str(f), lbl))\n\nif not samples:\n    raise RuntimeError(\"No test images found in /kaggle/working/dataset_sampled/test. Check your dataset path.\")\n\n# 4) Compute Grad-CAM and display\nplt.figure(figsize=(12, 8))\nfor idx, (fp, label) in enumerate(samples[:6]):\n    img = kimage.load_img(fp, target_size=IMG_SIZE)\n    x = kimage.img_to_array(img) / 255.0\n    x_exp = np.expand_dims(x, axis=0).astype(np.float32)\n\n    # prediction\n    pred = float(model.predict(x_exp, verbose=0).ravel()[0])\n\n    # heatmap\n    heatmap = make_gradcam_heatmap(x_exp, model, last_conv)\n\n    # upsample heatmap to image size and apply color\n    heat = cv2.resize((heatmap * 255).astype(np.uint8), (IMG_SIZE[1], IMG_SIZE[0]))\n    heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)\n    img_rgb = (x * 255).astype(np.uint8)\n    superimposed = cv2.addWeighted(img_rgb, 0.6, heat, 0.4, 0)\n\n    plt.subplot(3, 2, idx + 1)\n    plt.imshow(superimposed.astype(np.uint8))\n    plt.title(f\"{label}  pred:{pred:.3f}\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T16:56:49.510362Z","iopub.execute_input":"2025-12-07T16:56:49.511212Z","iopub.status.idle":"2025-12-07T16:56:54.955127Z","shell.execute_reply.started":"2025-12-07T16:56:49.511177Z","shell.execute_reply":"2025-12-07T16:56:54.954090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Save Grad-CAM images to disk**","metadata":{}},{"cell_type":"code","source":"# Save Grad-CAM images to disk\nimport numpy as np, cv2, os\nfrom tensorflow.keras.preprocessing import image as kimage\nfrom pathlib import Path\n\nOUT = Path(\"/kaggle/working/gradcam_outputs\")\nOUT.mkdir(parents=True, exist_ok=True)\n\n# reuse make_gradcam_heatmap() and last_conv from your notebook\n# sample images\ntest_root = Path(\"/kaggle/working/dataset_sampled/test\")\nsamples = []\nfor lbl in (\"real\",\"spoof\"):\n    p = test_root / lbl\n    for f in sorted(p.glob(\"*\"))[:3]:\n        samples.append((str(f), lbl))\n\nfor idx,(fp,label) in enumerate(samples[:12]):\n    img = kimage.load_img(fp, target_size=(224,224))\n    x = kimage.img_to_array(img)/255.0\n    x_exp = np.expand_dims(x, axis=0).astype(np.float32)\n    pred = float(model.predict(x_exp).ravel()[0])\n    heatmap = make_gradcam_heatmap(x_exp, model, last_conv)\n    heat = cv2.resize((heatmap*255).astype(np.uint8), (224,224))\n    heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)\n    img_rgb = (x*255).astype(np.uint8)\n    superimposed = cv2.addWeighted(img_rgb, 0.6, heat, 0.4, 0)\n    outp = OUT / f\"gradcam_{idx}_{label}_pred{pred:.3f}.png\"\n    cv2.imwrite(str(outp), cv2.cvtColor(superimposed, cv2.COLOR_RGB2BGR))\nprint(\"Saved gradcam images to:\", OUT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T17:00:34.073534Z","iopub.execute_input":"2025-12-07T17:00:34.074249Z","iopub.status.idle":"2025-12-07T17:00:37.662175Z","shell.execute_reply.started":"2025-12-07T17:00:34.074222Z","shell.execute_reply":"2025-12-07T17:00:37.661286Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Face-detection cropping (Haar)  creates /kaggle/working/dataset_crops","metadata":{}},{"cell_type":"code","source":"\n\nimport cv2, os\nfrom pathlib import Path\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nSRC_ROOT = Path(\"/kaggle/working/dataset_sampled\")\nOUT_ROOT = Path(\"/kaggle/working/dataset_crops\")\nOUT_ROOT.mkdir(parents=True, exist_ok=True)\n\nhaar_path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\ndetector = cv2.CascadeClassifier(haar_path)\nprint(\"Using Haar cascade:\", haar_path)\n\ndef crop_and_save(src_path, dst_path, size=(224,224)):\n    img = cv2.imread(str(src_path))\n    if img is None:\n        return False\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    # detect faces (scaleFactor & minNeighbors tuned for variety)\n    faces = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(30,30))\n    if len(faces) == 0:\n        # fallback: try a larger window or center-crop if no face found\n        h,w = img.shape[:2]\n        min_side = min(h,w)\n        cx,cy = w//2, h//2\n        half = min_side//2\n        x = max(0, cx-half); y = max(0, cy-half)\n        crop = img[y:y+2*half, x:x+2*half]\n    else:\n        # pick largest face\n        x,y,w,h = max(faces, key=lambda r: r[2]*r[3])\n        pad = int(0.25 * max(w,h))  # small padding\n        x1 = max(0, x - pad); y1 = max(0, y - pad)\n        x2 = min(img.shape[1], x + w + pad); y2 = min(img.shape[0], y + h + pad)\n        crop = img[y1:y2, x1:x2]\n\n    try:\n        crop = cv2.resize(crop, size)\n    except Exception:\n        return False\n    dst_path.parent.mkdir(parents=True, exist_ok=True)\n    cv2.imwrite(str(dst_path), crop)\n    return True\n\n# iterate splits and labels\ntotal = 0\nfailed = 0\nfor split in [\"train\",\"val\",\"test\"]:\n    for label in [\"real\",\"spoof\"]:\n        src_dir = SRC_ROOT / split / label\n        out_dir = OUT_ROOT / split / label\n        out_dir.mkdir(parents=True, exist_ok=True)\n        if not src_dir.exists(): \n            continue\n        for p in sorted(src_dir.glob(\"*\")):\n            out_p = out_dir / p.name\n            ok = crop_and_save(p, out_p)\n            total += 1\n            if not ok:\n                failed += 1\nprint(f\"Cropped images saved under {OUT_ROOT}  (total processed: {total}, failed: {failed})\")\n# quick counts\nfor split in [\"train\",\"val\",\"test\"]:\n    for label in [\"real\",\"spoof\"]:\n        print(f\"{split}/{label} ->\", len(list((OUT_ROOT/split/label).glob(\"*\"))))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T17:08:36.244685Z","iopub.execute_input":"2025-12-07T17:08:36.245035Z","iopub.status.idle":"2025-12-07T17:08:51.206753Z","shell.execute_reply.started":"2025-12-07T17:08:36.245013Z","shell.execute_reply":"2025-12-07T17:08:51.205858Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Batch inference + Grad-CAM + CSV results**","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np, os, cv2, math\nfrom pathlib import Path\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image as kimage\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# CONFIG\nMODEL_PATH = \"/kaggle/working/antispoof_mobilenet_best.h5\"  # change if different\nCROP_ROOT = Path(\"/kaggle/working/dataset_crops/test\")\nOUT_DIR = Path(\"/kaggle/working/gradcam_outputs\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\nIMG_SIZE = (224,224)\n\n# load model (best checkpoint)\nif not Path(MODEL_PATH).exists():\n    raise FileNotFoundError(f\"Model not found at {MODEL_PATH}  save checkpoint or adjust MODEL_PATH.\")\nmodel = load_model(MODEL_PATH)\nprint(\"Model loaded:\", MODEL_PATH)\n\n# find last conv layer robustly\nlast_conv = None\nfor l in reversed(model.layers):\n    shp = getattr(l, \"output_shape\", None)\n    if shp is None:\n        out = getattr(l, \"output\", None)\n        if out is not None:\n            shp = getattr(out, \"shape\", None)\n    try:\n        if shp is not None:\n            # convert to list\n            if hasattr(shp, \"as_list\"):\n                shp_list = shp.as_list()\n            else:\n                shp_list = tuple(shp)\n            if shp_list and len(shp_list) == 4:\n                last_conv = l.name\n                break\n    except Exception:\n        continue\nif last_conv is None:\n    raise RuntimeError(\"Could not find conv layer automatically. Provide model.summary() output.\")\nprint(\"Using last conv layer:\", last_conv)\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, eps=1e-8):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_outputs, preds = grad_model(img_array)\n        loss = preds[:, 0]\n    grads = tape.gradient(loss, conv_outputs)\n    if grads is None:\n        return np.zeros((conv_outputs.shape[1], conv_outputs.shape[2]), dtype=np.float32)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0)\n    denom = tf.math.reduce_max(heatmap) + eps\n    heatmap = heatmap / denom\n    return heatmap.numpy()\n\nresults = []\ny_true, y_pred_scores = [], []\ntest_images = []\n\nfor label in (\"real\",\"spoof\"):\n    folder = CROP_ROOT / label\n    if not folder.exists(): continue\n    for fp in sorted(folder.glob(\"*\")):\n        try:\n            img = kimage.load_img(fp, target_size=IMG_SIZE)\n            x = kimage.img_to_array(img) / 255.0\n            x_exp = np.expand_dims(x, axis=0).astype(np.float32)\n            score = float(model.predict(x_exp, verbose=0).ravel()[0])  # sigmoid score\n            pred_class = 1 if score>0.5 else 0\n            results.append({\"path\": str(fp), \"true\": label, \"true_bin\": 1 if label==\"spoof\" else 0, \"score\": score, \"pred\": pred_class})\n            y_true.append(1 if label==\"spoof\" else 0)\n            y_pred_scores.append(score)\n            test_images.append(fp)\n        except Exception as e:\n            print(\"Skipping\", fp, \"->\", e)\n\n# Save CSV\ndf = pd.DataFrame(results)\nout_csv = Path(\"/kaggle/working/predictions.csv\")\ndf.to_csv(out_csv, index=False)\nprint(\"Predictions saved to\", out_csv)\nprint(\"Total predicted:\", len(df))\n\n# Confusion matrix & classification report\nif len(df)==0:\n    raise RuntimeError(\"No predictions were made; check CROP_ROOT path: \" + str(CROP_ROOT))\n\ny_true_arr = df[\"true_bin\"].values\ny_pred_bin = (df[\"score\"].values > 0.5).astype(int)\nprint(\"\\nClassification report:\")\nprint(classification_report(y_true_arr, y_pred_bin, target_names=[\"real\",\"spoof\"]))\n\ncm = confusion_matrix(y_true_arr, y_pred_bin)\nplt.figure(figsize=(4,3))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"real\",\"spoof\"], yticklabels=[\"real\",\"spoof\"])\nplt.xlabel(\"Pred\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix\"); plt.show()\n\n# Generate and save Grad-CAM images for top-K sample images (K=12)\nK = 12\nfor idx, row in df.sort_values(\"score\", ascending=False).head(K).iterrows():\n    fp = Path(row[\"path\"])\n    img = kimage.load_img(fp, target_size=IMG_SIZE)\n    x = kimage.img_to_array(img) / 255.0\n    x_exp = np.expand_dims(x, axis=0).astype(np.float32)\n    heatmap = make_gradcam_heatmap(x_exp, model, last_conv)\n    heat = cv2.resize((heatmap*255).astype(np.uint8), (IMG_SIZE[1], IMG_SIZE[0]))\n    heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)\n    img_rgb = (x*255).astype(np.uint8)\n    superimposed = cv2.addWeighted(img_rgb, 0.6, heat, 0.4, 0)\n    outp = OUT_DIR / f\"gradcam_top_{idx}_{fp.name}_score{row['score']:.3f}.png\"\n    cv2.imwrite(str(outp), cv2.cvtColor(superimposed, cv2.COLOR_RGB2BGR))\n\nprint(\"Saved Grad-CAM images to:\", OUT_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T17:10:03.925798Z","iopub.execute_input":"2025-12-07T17:10:03.926715Z","iopub.status.idle":"2025-12-07T17:10:12.665232Z","shell.execute_reply.started":"2025-12-07T17:10:03.926683Z","shell.execute_reply":"2025-12-07T17:10:12.664232Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**RESAMPLE with larger N_PER_CLASS + retrain**","metadata":{}},{"cell_type":"code","source":"\nfrom pathlib import Path\nimport shutil, random, os\nSRC_CELEBA = Path(\"/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/Data\")\nSRC_PRINT = Path(\"/kaggle/input/photo-print-attacks-dataset-1k-individuals\")\nDST = Path(\"/kaggle/working/dataset_sampled_big\")\n\nN_PER_CLASS = 1000   # set 600 or 400 if you have runtime concerns; 1000 gives better results\nif DST.exists():\n    print(\"Removing old folder\", DST)\n    shutil.rmtree(DST)\nfor split in (\"train\",\"val\",\"test\"):\n    for lbl in (\"real\",\"spoof\"):\n        (DST/split/lbl).mkdir(parents=True, exist_ok=True)\n\ndef detect_label_from_path(p:Path):\n    s = str(p).lower()\n    if any(k in s for k in (\"live\",\"real\",\"genuine\")): return \"real\"\n    if any(k in s for k in (\"spoof\",\"attack\",\"print\",\"replay\",\"photo\",\"display\",\"screen\",\"fake\")): return \"spoof\"\n    return None\n\n# Helper: fast gather limited items per label from a source root by searching limited depth\ndef sample_from_root(root, n_per=N_PER_CLASS):\n    found = {\"real\":0,\"spoof\":0}\n    if not root.exists(): return found\n    # target pattern walking that matches the structure; sample without scanning everything\n    # iterate top-level children, then their subfolders\n    for a in sorted(root.iterdir()):\n        if found[\"real\"]>=n_per and found[\"spoof\"]>=n_per:\n            break\n        for b in sorted(a.rglob(\"*\")):\n            if found[\"real\"]>=n_per and found[\"spoof\"]>=n_per:\n                break\n            if b.is_file() and b.suffix.lower() in (\".jpg\",\".jpeg\",\".png\"):\n                lbl = detect_label_from_path(b)\n                if lbl is None:\n                    # fallback: treat as real if no spoof keywords\n                    lbl = \"real\"\n                if found[lbl] < n_per:\n                    # place into train/val/test randomly\n                    r = random.random()\n                    if r < 0.7: split=\"train\"\n                    elif r < 0.85: split=\"val\"\n                    else: split=\"test\"\n                    dst = DST/split/lbl/b.name\n                    try:\n                        shutil.copy(b, dst)\n                        found[lbl] += 1\n                    except Exception:\n                        pass\n    return found\n\nprint(\"Sampling from CelebA (may take a little time)...\")\nc1 = sample_from_root(SRC_CELEBA, N_PER_CLASS)\nprint(\"CelebA counts:\", c1)\nprint(\"Sampling from Photo-Print (may be smaller)...\")\nc2 = sample_from_root(SRC_PRINT, N_PER_CLASS//2)  # PhotoPrint smaller  take fewer\nprint(\"Photo-Print counts:\", c2)\n\n# quick summary\nfor split in (\"train\",\"val\",\"test\"):\n    print(split, \"-> real:\", len(list((DST/split/\"real\").glob(\"*\"))), \"spoof:\", len(list((DST/split/\"spoof\").glob(\"*\"))))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:13:53.024258Z","iopub.execute_input":"2025-12-09T15:13:53.024518Z","iopub.status.idle":"2025-12-09T15:20:54.788156Z","shell.execute_reply.started":"2025-12-09T15:13:53.024495Z","shell.execute_reply":"2025-12-09T15:20:54.787072Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Training cell tuned for bigger dataset**","metadata":{}},{"cell_type":"code","source":"# Training with stronger augmentation + focal loss option\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nBASE = \"/kaggle/working/dataset_sampled_big\"\nIMG_SIZE=(224,224)\nBATCH=32\n\n# stronger augmentation: add gaussian noise & jpeg corruption via preprocessing_function\nimport numpy as np\nimport cv2\ndef random_augment(img):\n    # img: float32 array [0,1]\n    # random gaussian blur\n    if np.random.rand() < 0.3:\n        k = np.random.choice([3,5])\n        img = cv2.GaussianBlur((img*255).astype(np.uint8), (k,k), 0)/255.0\n    # jpeg compression\n    if np.random.rand() < 0.2:\n        encode = cv2.imencode('.jpg', (img*255).astype(np.uint8), [int(cv2.IMWRITE_JPEG_QUALITY), np.random.randint(30,90)])[1]\n        img = cv2.imdecode(encode, cv2.IMREAD_COLOR)[:,:,::-1]/255.0\n    # random brightness\n    if np.random.rand() < 0.3:\n        factor = 0.7 + np.random.rand()*0.6\n        img = np.clip(img * factor, 0, 1)\n    # add noise\n    if np.random.rand() < 0.2:\n        img = np.clip(img + np.random.normal(scale=0.02, size=img.shape), 0, 1)\n    return img\n\n# wrapper for ImageDataGenerator preprocessing (expects 0-255 uint image)\ndef preprocess_fn(x):\n    x = x.astype(np.float32)/255.0\n    x = random_augment(x)\n    return x\n\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_fn,\n                                   horizontal_flip=True, fill_mode='nearest')\nval_datagen = ImageDataGenerator(rescale=1./255.0)\n\ntrain_gen = train_datagen.flow_from_directory(os.path.join(BASE,\"train\"), target_size=IMG_SIZE, batch_size=BATCH, class_mode='binary', shuffle=True)\nval_gen   = val_datagen.flow_from_directory(os.path.join(BASE,\"val\"), target_size=IMG_SIZE, batch_size=BATCH, class_mode='binary', shuffle=False)\n\n# build model\nbase = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0],IMG_SIZE[1],3))\nx = GlobalAveragePooling2D()(base.output)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nout = Dense(1, activation='sigmoid')(x)\nmodel = Model(base.input, out)\nfor layer in base.layers:\n    layer.trainable=False\n\n# optional focal loss (uncomment if desired)\n# def focal_loss(gamma=2., alpha=.25):\n#     def fl(y_true, y_pred):\n#         y_pred = tf.keras.backend.clip(y_pred, 1e-7, 1-1e-7)\n#         pt = tf.where(tf.equal(y_true,1), y_pred, 1-y_pred)\n#         return -alpha * tf.keras.backend.pow(1-pt, gamma) * tf.keras.backend.log(pt)\n#     return fl\n# loss = focal_loss()\nloss = 'binary_crossentropy'\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=loss, metrics=['accuracy'])\n\nckpt = \"/kaggle/working/antispoof_big_mobilenet_best.h5\"\ncallbacks=[ModelCheckpoint(ckpt, monitor='val_accuracy', save_best_only=True, verbose=1),\n           ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n           EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)]\n\nEPOCHS=20\nhistory = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=callbacks)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:22:25.530676Z","iopub.execute_input":"2025-12-09T15:22:25.531712Z","iopub.status.idle":"2025-12-09T15:39:23.276687Z","shell.execute_reply.started":"2025-12-09T15:22:25.531677Z","shell.execute_reply":"2025-12-09T15:39:23.275228Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate on test set","metadata":{}},{"cell_type":"code","source":"# EVAL CELL: classification report, confusion matrix, ROC/AUC, save preds CSV\nimport os, numpy as np, pandas as pd\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt, seaborn as sns\n\nCKPT = \"/kaggle/working/antispoof_big_mobilenet_best.h5\"   \nBASE = \"/kaggle/working/dataset_sampled_big\"               \nIMG_SIZE = (224,224)\n\nif not os.path.exists(CKPT):\n    print(\"Checkpoint not found at\", CKPT)\nelse:\n    model = load_model(CKPT)\n    print(\"Loaded model:\", CKPT)\n\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    test_gen = test_datagen.flow_from_directory(os.path.join(BASE,\"test\"),\n                                                target_size=IMG_SIZE, batch_size=1,\n                                                class_mode='binary', shuffle=False)\n    preds = model.predict(test_gen, verbose=1)\n    scores = preds.ravel()\n    y_true = test_gen.classes\n    y_pred = (scores > 0.5).astype(int)\n\n    print(\"\\nClassification report:\")\n    print(classification_report(y_true, y_pred, target_names=list(test_gen.class_indices.keys())))\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(4,3))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=list(test_gen.class_indices.keys()), yticklabels=list(test_gen.class_indices.keys()))\n    plt.xlabel(\"Pred\"); plt.ylabel(\"True\"); plt.title(\"Confusion matrix\")\n    plt.show()\n\n    # ROC / AUC\n    try:\n        auc = roc_auc_score(y_true, scores)\n        fpr, tpr, thr = roc_curve(y_true, scores)\n        plt.figure(figsize=(5,4))\n        plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\n        plt.plot([0,1],[0,1],'k--')\n        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC\")\n        plt.legend(); plt.show()\n        print(\"AUC:\", auc)\n    except Exception as e:\n        print(\"Could not compute ROC/AUC:\", e)\n\n    # Save predictions CSV\n    fnames = np.array(test_gen.filenames)\n    df = pd.DataFrame({\"filename\": fnames, \"true\": y_true, \"score\": scores, \"pred\": y_pred})\n    df.to_csv(\"/kaggle/working/predictions_test.csv\", index=False)\n    print(\"Saved predictions to /kaggle/working/predictions_test.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:52:16.871104Z","iopub.execute_input":"2025-12-09T15:52:16.871502Z","iopub.status.idle":"2025-12-09T15:52:32.591736Z","shell.execute_reply.started":"2025-12-09T15:52:16.871474Z","shell.execute_reply":"2025-12-09T15:52:32.590747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Compute EER & ACER","metadata":{}},{"cell_type":"code","source":"# EER & ACER cell\nimport numpy as np\nfrom sklearn.metrics import roc_curve\n\n# expects y_true (0=real,1=spoof) and scores (higher -> more spoof)\n# If you ran the eval cell just above, y_true and scores are in memory.\n\ndef eer_from_scores(y_true, scores):\n    fpr, tpr, thresholds = roc_curve(y_true, scores)\n    fnr = 1 - tpr\n    idx = np.nanargmin(np.abs(fpr - fnr))\n    eer = (fpr[idx] + fnr[idx]) / 2.0\n    return eer, thresholds[idx], fpr, tpr\n\neer, thr_eer, fpr, tpr = eer_from_scores(y_true, scores)\nprint(\"EER (approx):\", eer, \"threshold at EER:\", thr_eer)\n\n# ACER calculation at chosen threshold (use thr_eer or 0.5)\nthreshold = thr_eer  # or 0.5\ny_pred_thr = (scores >= threshold).astype(int)\nAPCER = np.sum((y_true==1) & (y_pred_thr==0)) / np.sum(y_true==1)  # spoof classified as bona fide? adjust mapping if needed\nNPCER = np.sum((y_true==0) & (y_pred_thr==1)) / np.sum(y_true==0)\nACER = (APCER + NPCER)/2.0\nprint(f\"ACER @ threshold {threshold:.4f}: APCER={APCER:.4f}, NPCER={NPCER:.4f}, ACER={ACER:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:53:53.545963Z","iopub.execute_input":"2025-12-09T15:53:53.546888Z","iopub.status.idle":"2025-12-09T15:53:53.558562Z","shell.execute_reply.started":"2025-12-09T15:53:53.546854Z","shell.execute_reply":"2025-12-09T15:53:53.557285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Save Grad-CAM images for top-K (visual inspection)**","metadata":{}},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"\nimport os, cv2, numpy as np, pandas as pd, tensorflow as tf\nfrom pathlib import Path\nfrom tensorflow.keras.preprocessing import image as kimage\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\n\n# CONFIG: possible test roots to try (order matters)\npossible_roots = [\n    Path(\"/kaggle/working/dataset_sampled_big/test\"),\n    Path(\"/kaggle/working/dataset_sampled/test\"),\n    Path(\"/kaggle/working/dataset_quick/test\"),\n    Path(\"/kaggle/working/dataset_sampled/test\"),\n    Path(\"/kaggle/working/dataset_crops/test\"),\n    Path(\"/kaggle/working/dataset/test\")\n]\n\n# 1) Load predictions DataFrame (from memory or CSV)\nif \"df\" in globals():\n    df_preds = df.copy()\nelif Path(\"/kaggle/working/predictions_test.csv\").exists():\n    df_preds = pd.read_csv(\"/kaggle/working/predictions_test.csv\")\nelif Path(\"/kaggle/working/predictions.csv\").exists():\n    df_preds = pd.read_csv(\"/kaggle/working/predictions.csv\")\nelse:\n    raise FileNotFoundError(\"predictions_test.csv not found in /kaggle/working and df not present in memory.\")\n\n# 2) Determine test root automatically\ntest_root = None\nfor p in possible_roots:\n    if p.exists():\n        # ensure it contains some images / folders\n        try:\n            files = list(p.rglob(\"*\"))\n            if any(str(f.suffix).lower() in (\".jpg\",\".jpeg\",\".png\") for f in files[:10]):\n                test_root = p\n                break\n        except Exception:\n            continue\n\nif test_root is None:\n    print(\"Could not auto-detect test root from common locations. Please set TEST_ROOT manually.\")\n    print(\"Tried:\", [str(x) for x in possible_roots])\n    raise RuntimeError(\"Test root not found. If your test images are somewhere else, set TEST_ROOT variable to that folder.\")\n\nprint(\"Detected test root:\", test_root)\n\n# 3) Ensure model is loaded (tries to use 'model' if present; otherwise loads checkpoint)\nif 'model' not in globals():\n    CKPT = \"/kaggle/working/antispoof_big_mobilenet_best.h5\"\n    if not Path(CKPT).exists():\n        # try other likely names\n        for alt in [\"antispoof_mobilenet_best.h5\", \"antispoof_mobilenet_final.h5\", \"antispoof_mobilenet_best.h5\", \"antispoof_mobilenet.h5\"]:\n            if Path(\"/kaggle/working\")/alt .exists():\n                CKPT = str(Path(\"/kaggle/working\")/alt)\n                break\n    if not Path(CKPT).exists():\n        raise FileNotFoundError(\"Model 'model' not in memory and no checkpoint found in /kaggle/working/. Please set CKPT path.\")\n    print(\"Loading model from:\", CKPT)\n    model = tf.keras.models.load_model(CKPT)\n\n# 4) find last conv layer robustly\nlast_conv = None\nfor l in reversed(model.layers):\n    try:\n        shp = getattr(l, \"output_shape\", None)\n        if shp is None and getattr(l, \"output\", None) is not None:\n            shp = l.output.shape\n        if shp is not None:\n            if hasattr(shp, \"as_list\"):\n                shp_list = shp.as_list()\n            else:\n                shp_list = tuple(shp)\n            if shp_list and len(shp_list) == 4:\n                last_conv = l.name\n                break\n    except Exception:\n        continue\nif last_conv is None:\n    raise RuntimeError(\"Could not determine last conv layer automatically. Provide model.summary() to pick a conv layer name.\")\nprint(\"Using last conv layer:\", last_conv)\n\n# 5) Grad-CAM helper\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, eps=1e-8):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_outputs, preds = grad_model(img_array)\n        loss = preds[:, 0]\n    grads = tape.gradient(loss, conv_outputs)\n    if grads is None:\n        return np.zeros((conv_outputs.shape[1], conv_outputs.shape[2]), dtype=np.float32)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0)\n    denom = tf.math.reduce_max(heatmap) + eps\n    heatmap = heatmap / denom\n    return heatmap.numpy()\n\n# 6) Prepare outputs and selection\nOUT = Path(\"/kaggle/working/gradcam_inspect\")\nOUT.mkdir(parents=True, exist_ok=True)\n\n# If df contains relative filenames (like 'spoof/498220.png'), use test_root/fname\nfn_col = None\n# locate filename-like column\nfor c in [\"filename\",\"path\",\"file\",\"img\",\"image\"]:\n    if c in df_preds.columns:\n        fn_col = c; break\nif fn_col is None:\n    # fallback: take first column\n    fn_col = df_preds.columns[0]\n\n# Normalize filenames into absolute paths\nabs_paths = []\nnot_found = []\nfor idx, row in df_preds.iterrows():\n    raw = str(row[fn_col])\n    # if already absolute and exists -> use it\n    p = Path(raw)\n    if p.exists():\n        abs_paths.append(str(p))\n        continue\n    # try join with test_root\n    candidate = test_root / raw\n    if candidate.exists():\n        abs_paths.append(str(candidate))\n        continue\n    # sometimes filenames are stored as 'real/xxx' but nested under dataset_sampled_big/test/real/xxx\n    candidate2 = test_root / Path(raw).name  # only filename\n    if candidate2.exists():\n        abs_paths.append(str(candidate2)); continue\n    # try other depth: if raw is like 'spoof/498220.png' and dataset root is higher, try test_root.parent / raw\n    candidate3 = test_root.parent / raw\n    if candidate3.exists():\n        abs_paths.append(str(candidate3)); continue\n    # else mark not found\n    abs_paths.append(None)\n    not_found.append(raw)\n\n# attach resolved paths to df\ndf_preds[\"_abs_path\"] = abs_paths\n\nprint(f\"Total predictions: {len(df_preds)}, not found entries: {len([x for x in abs_paths if x is None])}\")\n\n# 7) Select top-K spoof and top-K real (by score) - handle column names\nscore_col = None\nfor c in [\"score\",\"pred_score\",\"prob\",\"probability\"]:\n    if c in df_preds.columns:\n        score_col = c; break\nif score_col is None:\n    # fallback to second numeric column\n    numeric_cols = df_preds.select_dtypes(include=[np.number]).columns.tolist()\n    score_col = numeric_cols[0] if numeric_cols else None\nif score_col is None:\n    raise RuntimeError(\"Cannot find score column in predictions dataframe.\")\n\n# choose K\nK = 12\ntop_spoof = df_preds.sort_values(score_col, ascending=False).head(K)\ntop_real  = df_preds.sort_values(score_col, ascending=True).head(K)\n\n# 8) Save cams (robust)\ndef save_cam_row(row, tag):\n    ap = row[\"_abs_path\"]\n    if ap is None or not Path(ap).exists():\n        print(\"Missing file, skipping:\", row.get(fn_col, \"(no name)\"))\n        return False\n    try:\n        img = kimage.load_img(ap, target_size=(224,224))\n        x = kimage.img_to_array(img)/255.0\n        x_exp = np.expand_dims(x, axis=0).astype(np.float32)\n        score = float(model.predict(x_exp, verbose=0).ravel()[0])\n        heatmap = make_gradcam_heatmap(x_exp, model, last_conv)\n        heat = cv2.resize((heatmap*255).astype(np.uint8), (224,224))\n        heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)\n        img_rgb = (x*255).astype(np.uint8)\n        sup = cv2.addWeighted(img_rgb, 0.6, heat, 0.4, 0)\n        outp = OUT / f\"{tag}_{Path(ap).stem}_score{score:.3f}.png\"\n        cv2.imwrite(str(outp), cv2.cvtColor(sup, cv2.COLOR_RGB2BGR))\n        return True\n    except Exception as e:\n        print(\"Error processing\", ap, \"->\", e)\n        return False\n\ncount_saved = 0\nfor _, r in top_spoof.iterrows():\n    if save_cam_row(r, \"top_spoof\"):\n        count_saved += 1\nfor _, r in top_real.iterrows():\n    if save_cam_row(r, \"top_real\"):\n        count_saved += 1\n\nprint(f\"Done. Saved {count_saved} Grad-CAM images to {OUT}\")\nif len(not_found)>0:\n    print(\"Some filenames were not found (examples):\", not_found[:10])\n    print(\"If you see many missing files, please confirm the test root, or provide the exact path used by your generator.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T16:02:27.361565Z","iopub.execute_input":"2025-12-09T16:02:27.361910Z","iopub.status.idle":"2025-12-09T16:02:44.950099Z","shell.execute_reply.started":"2025-12-09T16:02:27.361889Z","shell.execute_reply":"2025-12-09T16:02:44.948693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# View a few saved Grad-CAMs inside the notebook","metadata":{}},{"cell_type":"code","source":"from IPython.display import display\nfrom PIL import Image\nfrom pathlib import Path\np = Path(\"/kaggle/working/gradcam_inspect\")\nimgs = sorted(list(p.glob(\"*.png\")))[:8]\nprint(\"Showing\", len(imgs), \"images from\", p)\nfor im in imgs:\n    display(Image.open(im).resize((400,400)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T16:06:48.621972Z","iopub.execute_input":"2025-12-09T16:06:48.623110Z","iopub.status.idle":"2025-12-09T16:06:48.910178Z","shell.execute_reply.started":"2025-12-09T16:06:48.623076Z","shell.execute_reply":"2025-12-09T16:06:48.908819Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create a ZIP of all outputs (model, preds CSV, gradcams) for download","metadata":{}},{"cell_type":"code","source":"%%bash\ncd /kaggle/working\nzip -r antispoof_outputs.zip antispoof_big_mobilenet_best.h5 predictions_test.csv gradcam_inspect gradcam_outputs || true\nls -lh antispoof_outputs.zip\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T16:07:42.471487Z","iopub.execute_input":"2025-12-09T16:07:42.471873Z","iopub.status.idle":"2025-12-09T16:07:43.547993Z","shell.execute_reply.started":"2025-12-09T16:07:42.471849Z","shell.execute_reply":"2025-12-09T16:07:43.546677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Print short numeric summary from predictions (per-class AP/NP error / counts)**","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\ndf = pd.read_csv(\"/kaggle/working/predictions_test.csv\")\nprint(df.head())\n# mapping: assume true: 1==spoof, 0==real (if different, swap)\ntotal = len(df)\nprint(\"Total test samples:\", total)\nprint(\"Counts by true label:\\n\", df['true'].value_counts())\n# small summary by threshold 0.5\ndf['pred']= (df['score']>0.5).astype(int)\ntp = ((df['true']==1)&(df['pred']==1)).sum()\ntn = ((df['true']==0)&(df['pred']==0)).sum()\nfp = ((df['true']==0)&(df['pred']==1)).sum()\nfn = ((df['true']==1)&(df['pred']==0)).sum()\nprint(\"TP, TN, FP, FN:\", tp, tn, fp, fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T16:08:28.141867Z","iopub.execute_input":"2025-12-09T16:08:28.142886Z","iopub.status.idle":"2025-12-09T16:08:28.161628Z","shell.execute_reply.started":"2025-12-09T16:08:28.142854Z","shell.execute_reply":"2025-12-09T16:08:28.160114Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Tune a threshold using EER & save thresholded preds**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import roc_curve\ndf = pd.read_csv(\"/kaggle/working/predictions_test.csv\")\ny = df['true'].values\nscores = df['score'].values\nfpr,tpr,thr = roc_curve(y,scores)\nfnr = 1 - tpr\nidx = np.nanargmin(np.abs(fpr - fnr))\neer_thr = thr[idx]\nprint(\"EER threshold:\", eer_thr)\ndf['pred_eer'] = (df['score'] >= eer_thr).astype(int)\ndf.to_csv(\"/kaggle/working/predictions_test_with_eer.csv\", index=False)\nprint(\"Saved predictions with EER-threshold to predictions_test_with_eer.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T16:09:43.194323Z","iopub.execute_input":"2025-12-09T16:09:43.194666Z","iopub.status.idle":"2025-12-09T16:09:43.211310Z","shell.execute_reply.started":"2025-12-09T16:09:43.194642Z","shell.execute_reply":"2025-12-09T16:09:43.210104Z"}},"outputs":[],"execution_count":null}]}